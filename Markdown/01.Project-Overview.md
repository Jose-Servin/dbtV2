# Getting started with dbt

## Project Overview

Role: Data Engineer at Airbnb

General Tasks:

* Load, clean and expose data
* Write tests, automation and documentation

Data source:

* Inside Airbnb Berlin data

Tech Stack

* dbt, Snowflake and Preset (BI)

## Step 1: dbt + Snowflake Setup

After signing up for a trial account, we have to perform the following steps in Snowflake.

1. Setup dbt user

2. Create Airbnb database

See [notes](https://github.com/nordquant/complete-dbt-bootcamp-zero-to-hero/blob/main/_course_resources/course-resources.md)

## Step 2: dbt configuration

Next, we go into our dbt project repo and run through these steps:

1. We run `mkdir ~.dbt`.

2. In our project folder `dbtReview` we run `dbt init dbtlearnV2` and answer setup questions.

3. We `cd dbtlearnV2` and run `dbt debug` to verify if the Snowflake connection was successful.

## Understanding our dbt Folder Structure

From our `dbtReview` folder, if we run `tree` we see

 ```text
.
├── dbtlearnV2
│   ├── README.md
│   ├── analyses
│   ├── dbt_project.yml
│   ├── logs
│   │   └── dbt.log
│   ├── macros
│   ├── models
│   │   └── example
│   │       ├── my_first_dbt_model.sql
│   │       ├── my_second_dbt_model.sql
│   │       └── schema.yml
│   ├── seeds
│   ├── snapshots
│   └── tests
└── logs
    └── dbt.log
 ```

### dbt_project.yml

dbt project level configurations. Here we will see project folder paths defined as well as how `models` get materialized.

`name:` is the name we provided when running `dbt init {project-name}`.

Here, we deleted the settings configurations for `models` and the 2 example `models` created by default.

### dbt Power User

After installing the VSCode extension, we created a `.vscode/` directory to hold our workspace `settings.json` file.

```json
{"files.associations": {
    "*.sql" : "jinja-sql"
}}
```

## Step 3: Building our Data Flow

### Input Data Models

1. Listings
2. Hosts
3. Reviews
4. Full Moon Dates

Note: Full Moon Dates will help us see if a correlation exists between full moons and Airbnb review sentiments. "Do full moons negatively or positively affect Airbnb reviews?"

![Data Flow](../images/data-flow.png)

![Data DAG](../images/data-DAG.png)

## Source Models

The first Models we will create in our dbt project is our `src_{model-name}.sql` "source" models.

* src_hosts
* src_listings
* src_reviews

![Source Models](../images/source-models.png)

After defining our `src_listings` in Snowflake, we take our query and create a `models/src/src_listings.sql` file for dbt to execute with `dbt run`. Reminder to make sure we are in our `dbtlearnV2` folder.

![dbt run](../images/dbt-run.png)

## Materialization Overview

![Materialization Notes](../images/materialization-notes.png)

## Core Layer Models

After building our source models, we move on to the "Core Layer."

![Core Layer Models](../images/core-layer-models.png)

When building the core layer models, it's best practice to be explicit with our model's materialization. To achieve this, we will add a global configuration to our `dbt_project.yml` file.

```yml
# dtb_project.yml
models:
  dbtlearnV2:
    +materialized: view
```

After applying this configuration, we then materialize our `dim` models as tables because they represent "ready to use" data and will be used often for downstream model creation. If we leave our `dim` models are views, we will be executing the underlying sql statement each time we reference the dim model.

```yml
models:
  dbtlearnV2:
    +materialized: view
    dim:
      +materialized: table
```

![View Materialization](../images/view-materialization.png)

After running `dbt run` we see

![Table Materialization](../images/table-materialization.png)

Our `dim_hosts_cleaned.sql` model has an materialization as view config in the .sql file so it does not get materialized as a table. This shows us we can control each model's materialization independent from our global configurations.

### Incremental Materialization

For our `fct_reviews` model, we will be using an incremental materialization.

```sql
{{
    config(
        materialized = 'incremental',
        on_schema_change='fail'
    )
}}
WITH src_reviews AS (
    SELECT * FROM {{ ref('src_reviews') }}
)

SELECT * FROM src_reviews
WHERE review_text is not null

{% if is_incremental() %}
    AND review_date > (select max(review_date) from {{ this }})
{% endif %}
```

The incremental part of this model comes from the `.sql` configuration we define at the top of our sql file. Note: `this` refers to our `fct_reviews` model.

With this defined `incremental` materialization, we next define what logic dbt should use to increment. "What defines a new record?"

For `fct_reviews`, we are saying a new record(s) are any from `src_reviews` that have a review date greater than the max review date currently present in our `fct_reviews` table. Now, we have to go one step further and look at `src_reviews` which is a view built from `raw_reviews`. This is why, when we test the incremental loading, we will add a record to `raw_reviews` and not directly to `src_reviews`. If we were to add this new record to `src_reviews` then it would contain a record not present in it's source which is the wrong way to go about this incremental load building.

This is why on the first `dbt run` all records from `src_reviews` are added to the `fct_reviews` model because there is no max date present, the model does not "exist."

To test this incremental loading, we can take a look at listing `3176` from our `fct_reviews` model. We then add a record to our `raw_reviews` model and perform a `dbt run --full-refresh` to "pick up the changes." First, `src_reviews` will get re-built with this new record and then `fct_reviews` will get this record incrementally added.

Row added:

```sql
INSERT INTO "AIRBNB"."RAW"."RAW_REVIEWS"
VALUES (3176, CURRENT_TIMESTAMP(), 'Servin', 'excellent stay!', 'positive');
```

Verification:

```sql
SELECT * FROM AIRBNB.RAW.RAW_REVIEWS
WHERE REVIEWER_NAME = 'Servin';
```

`dbt run --full-refresh`

```terminal
14:15:49  Finished running 4 view models, 1 table model, 1 incremental model in 0 hours 0 minutes and 12.72 seconds (12.72s).
14:15:49
14:15:49  Completed successfully
14:15:49
14:15:49  Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
```

Snowflake Verification:

After running this Snowflake verification script, we should see our 'Servin' review in our `fct_reviews` model.

```sql
SELECT * FROM "AIRBNB"."DEV"."FCT_REVIEWS" WHERE listing_id=3176;
```
